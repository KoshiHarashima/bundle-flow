#!/usr/bin/env python3
"""
ãƒ‡ãƒã‚¤ã‚¹ç§»å‹•ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
PyTorchã®ãƒ‡ãƒã‚¤ã‚¹ç§»å‹•ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
"""

import torch
import sys

def test_device_availability():
    """ãƒ‡ãƒã‚¤ã‚¹ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” Testing device availability...")
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    print(f"MPS available: {torch.backends.mps.is_available()}")
    print(f"MPS built: {torch.backends.mps.is_built()}")
    
    # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… Selected device: {device}")
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        print(f"âœ… Selected device: {device}")
    else:
        device = torch.device("cpu")
        print(f"âš ï¸  Selected device: {device} (no GPU acceleration)")
    
    return device

def test_tensor_movement(device):
    """ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ç§»å‹•ã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ§ª Testing tensor movement to {device}...")
    
    # CPUä¸Šã§ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    x = torch.randn(100, 100)
    print(f"Original tensor device: {x.device}")
    
    # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
    x_device = x.to(device)
    print(f"Moved tensor device: {x_device.device}")
    
    # è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    y = torch.randn(100, 100, device=device)
    z = torch.mm(x_device, y)
    print(f"Matrix multiplication result device: {z.device}")
    print(f"Result shape: {z.shape}")
    
    return True

def test_model_movement(device):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ç§»å‹•ã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ§ª Testing model movement to {device}...")
    
    # ç°¡å˜ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    model = torch.nn.Linear(100, 50)
    print(f"Original model device: {next(model.parameters()).device}")
    
    # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
    model = model.to(device)
    print(f"Moved model device: {next(model.parameters()).device}")
    
    # æ¨è«–ãƒ†ã‚¹ãƒˆ
    x = torch.randn(10, 100, device=device)
    y = model(x)
    print(f"Model output device: {y.device}")
    print(f"Model output shape: {y.shape}")
    
    return True

def test_memory_management(device):
    """ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ§ª Testing memory management on {device}...")
    
    if device.type == "cuda":
        print(f"GPU memory before: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
        
        # å¤§ããªãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
        x = torch.randn(1000, 1000, device=device)
        print(f"GPU memory after allocation: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del x
        torch.cuda.empty_cache()
        print(f"GPU memory after cleanup: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
        
    elif device.type == "mps":
        print("MPS memory management test...")
        
        # å¤§ããªãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
        x = torch.randn(1000, 1000, device=device)
        print(f"MPS tensor created: {x.shape}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del x
        torch.mps.empty_cache()
        print("MPS memory cleaned up")
    
    return True

def main():
    print("ğŸš€ PyTorch Device Movement Test")
    print("=" * 50)
    
    try:
        # 1. ãƒ‡ãƒã‚¤ã‚¹åˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ
        device = test_device_availability()
        
        # 2. ãƒ†ãƒ³ã‚½ãƒ«ç§»å‹•ãƒ†ã‚¹ãƒˆ
        test_tensor_movement(device)
        
        # 3. ãƒ¢ãƒ‡ãƒ«ç§»å‹•ãƒ†ã‚¹ãƒˆ
        test_model_movement(device)
        
        # 4. ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ
        test_memory_management(device)
        
        print("\nğŸ‰ All tests passed!")
        print(f"âœ… Device {device} is ready for training!")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
