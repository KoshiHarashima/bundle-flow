{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWxyFTdZO2t"
      },
      "source": [
        "# BundleFlow Colab Demo\n",
        "\n",
        "** Rectified Flowâ€“based menus for combinatorial auctions**\n",
        "\n",
        "This notebook demonstrates menu optimization for combinatorial auctions using BundleFlow's new API structure.\n",
        "\n",
        "##  Table of Contents\n",
        "1. [Environment Setup](#setup)\n",
        "2. [New API Structure Demo](#api-demo)\n",
        "3. [Stage1: Flow Initialization](#stage1)\n",
        "4. [Stage2: Menu Optimization](#stage2)\n",
        "5. [Results Visualization](#visualization)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKolN5ONZO2u",
        "outputId": "e67851f9-4351-411e-b01d-e7c8952fb230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Matplotlib configuration completed\n"
          ]
        }
      ],
      "source": [
        "# Matplotlib configuration for clean plots\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# Set clean font configuration\n",
        "# Use a font generally available in Colab environments\n",
        "matplotlib.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False  # Fix minus sign display\n",
        "\n",
        "print(\"âœ… Matplotlib configuration completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODsPxBbZO2u"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's check the GPU environment and install necessary packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvU0Lr0YZO2u",
        "outputId": "7319823d-6433-4e23-ffc1-f96762155346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Oct 13 01:24:22 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU environment\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGUft88XZO2v",
        "outputId": "c7e6a4cc-b02e-4be9-b4dc-07d8952bc3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install omegaconf tqdm numpy matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbnPPvYMZO2v",
        "outputId": "3eb75a40-5469-4bfa-a174-b9bd3f239551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch and CUDA\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbirvEvSZO2v",
        "outputId": "83d7725b-2ee5-4baa-fc80-ce1f92d89330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/bundle-flow\n"
          ]
        }
      ],
      "source": [
        "# Colab-specific setup\n",
        "%cd /content/bundle-flow\n",
        "import sys\n",
        "sys.path.append('/content/bundle-flow/bundleflow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIhxYfBMZO2v"
      },
      "source": [
        "## 2. Demo\n",
        "\n",
        "Let's introduce BundleFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtPXX3hOZO2v",
        "outputId": "4d1e0e20-8d92-4c56-e0fe-613a2add7102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… New API structure import completed\n",
            "PyTorch device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# BundleFlow's new API\n",
        "from bundleflow.models.flow import BundleFlow\n",
        "from bundleflow.models.menu import MenuElement, Mechanism\n",
        "from bundleflow.valuation.valuation import XORValuation\n",
        "\n",
        "print(\" New API structure import completed\")\n",
        "print(f\"PyTorch device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLHTs708ZO2v",
        "outputId": "705a88da-fe5c-4177-8d0f-6d55c0ddec6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "âœ… BundleFlow created with m=10\n",
            "âœ… Velocity field shape: torch.Size([3, 10])\n",
            "âœ… MenuElement created with price: 0.0767\n",
            "âœ… XORValuation value: 8.0000\n"
          ]
        }
      ],
      "source": [
        "# Basic API demonstration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. Create BundleFlow (velocity field network)\n",
        "m = 10  # Number of items\n",
        "flow = BundleFlow(m=m).to(device)\n",
        "print(f\"BundleFlow created with m={m}\")\n",
        "\n",
        "# 2. Calculate velocity field\n",
        "x = torch.randn(3, m, device=device)\n",
        "t = torch.rand(3, device=device)\n",
        "v = flow.velocity(x, t)\n",
        "print(f\"Velocity field shape: {v.shape}\")\n",
        "\n",
        "# 3. Create MenuElement (menu element)\n",
        "D = 5  # Number of mixture components for initial distribution\n",
        "elem = MenuElement(m=m, D=D).to(device)\n",
        "price = elem.price()\n",
        "print(f\"MenuElement created with price: {price.detach().item():.4f}\")\n",
        "\n",
        "# 4. Create XORValuation (valuation function)\n",
        "atoms = [([1, 2, 3], 5.0), ([4, 5], 3.0), ([6, 7, 8, 9], 8.0)]\n",
        "valuation = XORValuation.from_bundle_list(m, atoms)\n",
        "bundle = torch.tensor([1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0])\n",
        "value = valuation.value(bundle)\n",
        "print(f\"XORValuation value: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RGVYdXJZO2v"
      },
      "source": [
        "## 3. Stage1: Flow Initialization\n",
        "\n",
        "Train the velocity field network to learn the transformation from continuous variables to discrete bundles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epBI6Z0PZO2w",
        "outputId": "8cd8444c-d5d9-49d5-fb55-f7b3d4f9409a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage1 Configuration:\n",
            "  m: 10\n",
            "  D: 4\n",
            "  iters: 20000\n",
            "  batch: 512\n",
            "  lr: 0.0005\n",
            "  sigma_z: 0.05\n",
            "  ode_steps: 50\n",
            "  seed: 42\n"
          ]
        }
      ],
      "source": [
        "# Stage1 configuration (10 items and small settings)\n",
        "stage1_config = {\n",
        "    'm': 10,           # Number of items (small scale)\n",
        "    'D': 4,           # Number of mixture components\n",
        "    'iters': 20000,    # Number of iterations (shortened for demo)\n",
        "    'batch': 512,     # Batch size\n",
        "    'lr': 5e-4,       # Learning rate\n",
        "    'sigma_z': 0.05,  # Noise standard deviation\n",
        "    'ode_steps': 50,  # ODE integration steps\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "print(\"Stage1 Configuration:\")\n",
        "for key, value in stage1_config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLH4SjvTZO2w",
        "outputId": "dc7e5a1a-475e-41f9-a122-b78be009fded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Stage1 training started (device: cuda)\n",
            "Model parameters: 51,685\n",
            "[100/20000] Loss: 1.315420 Time: 1.2s\n",
            "[200/20000] Loss: 1.269985 Time: 1.8s\n",
            "[300/20000] Loss: 1.279172 Time: 2.3s\n",
            "[400/20000] Loss: 1.252918 Time: 3.1s\n",
            "[500/20000] Loss: 1.232276 Time: 3.6s\n",
            "[600/20000] Loss: 1.224028 Time: 4.1s\n",
            "[700/20000] Loss: 1.225463 Time: 4.6s\n",
            "[800/20000] Loss: 1.243153 Time: 5.1s\n",
            "[900/20000] Loss: 1.256294 Time: 5.6s\n",
            "[1000/20000] Loss: 1.195550 Time: 6.1s\n",
            "[1100/20000] Loss: 1.267641 Time: 6.7s\n",
            "[1200/20000] Loss: 1.223283 Time: 7.2s\n",
            "[1300/20000] Loss: 1.260290 Time: 7.7s\n",
            "[1400/20000] Loss: 1.240617 Time: 8.2s\n",
            "[1500/20000] Loss: 1.275440 Time: 8.9s\n",
            "[1600/20000] Loss: 1.248467 Time: 9.5s\n",
            "[1700/20000] Loss: 1.223279 Time: 10.3s\n",
            "[1800/20000] Loss: 1.218199 Time: 10.8s\n",
            "[1900/20000] Loss: 1.221746 Time: 11.3s\n",
            "[2000/20000] Loss: 1.239031 Time: 11.8s\n",
            "[2100/20000] Loss: 1.226245 Time: 12.6s\n",
            "[2200/20000] Loss: 1.243025 Time: 13.1s\n",
            "[2300/20000] Loss: 1.277249 Time: 13.8s\n",
            "[2400/20000] Loss: 1.265564 Time: 14.4s\n",
            "[2500/20000] Loss: 1.262497 Time: 14.9s\n",
            "[2600/20000] Loss: 1.248201 Time: 15.4s\n",
            "[2700/20000] Loss: 1.213098 Time: 16.0s\n",
            "[2800/20000] Loss: 1.221952 Time: 16.5s\n",
            "[2900/20000] Loss: 1.238190 Time: 17.0s\n",
            "[3000/20000] Loss: 1.223058 Time: 17.5s\n",
            "[3100/20000] Loss: 1.221192 Time: 18.0s\n",
            "[3200/20000] Loss: 1.229893 Time: 18.5s\n",
            "[3300/20000] Loss: 1.211992 Time: 19.0s\n",
            "[3400/20000] Loss: 1.228898 Time: 19.6s\n",
            "[3500/20000] Loss: 1.210372 Time: 20.4s\n",
            "[3600/20000] Loss: 1.216638 Time: 21.2s\n",
            "[3700/20000] Loss: 1.278148 Time: 22.8s\n",
            "[3800/20000] Loss: 1.244845 Time: 24.0s\n",
            "[3900/20000] Loss: 1.192776 Time: 24.9s\n",
            "[4000/20000] Loss: 1.255460 Time: 25.7s\n",
            "[4100/20000] Loss: 1.233543 Time: 26.2s\n",
            "[4200/20000] Loss: 1.213045 Time: 27.0s\n",
            "[4300/20000] Loss: 1.231731 Time: 27.5s\n",
            "[4400/20000] Loss: 1.215064 Time: 28.0s\n",
            "[4500/20000] Loss: 1.231556 Time: 28.5s\n",
            "[4600/20000] Loss: 1.169773 Time: 29.0s\n",
            "[4700/20000] Loss: 1.273479 Time: 29.6s\n",
            "[4800/20000] Loss: 1.235491 Time: 30.1s\n",
            "[4900/20000] Loss: 1.261251 Time: 30.6s\n",
            "[5000/20000] Loss: 1.236228 Time: 31.1s\n",
            "[5100/20000] Loss: 1.224098 Time: 31.6s\n",
            "[5200/20000] Loss: 1.197608 Time: 32.1s\n",
            "[5300/20000] Loss: 1.241649 Time: 32.6s\n",
            "[5400/20000] Loss: 1.194710 Time: 33.1s\n",
            "[5500/20000] Loss: 1.248966 Time: 33.8s\n",
            "[5600/20000] Loss: 1.233908 Time: 34.4s\n",
            "[5700/20000] Loss: 1.207780 Time: 35.1s\n",
            "[5800/20000] Loss: 1.230019 Time: 35.6s\n",
            "[5900/20000] Loss: 1.226779 Time: 36.1s\n",
            "[6000/20000] Loss: 1.201737 Time: 36.6s\n",
            "[6100/20000] Loss: 1.242525 Time: 37.1s\n",
            "[6200/20000] Loss: 1.226476 Time: 37.7s\n",
            "[6300/20000] Loss: 1.223205 Time: 38.2s\n",
            "[6400/20000] Loss: 1.201491 Time: 38.7s\n",
            "[6500/20000] Loss: 1.226989 Time: 39.2s\n",
            "[6600/20000] Loss: 1.234336 Time: 39.7s\n",
            "[6700/20000] Loss: 1.218320 Time: 40.2s\n",
            "[6800/20000] Loss: 1.210867 Time: 40.7s\n",
            "[6900/20000] Loss: 1.264258 Time: 41.2s\n",
            "[7000/20000] Loss: 1.266538 Time: 41.7s\n",
            "[7100/20000] Loss: 1.256131 Time: 42.2s\n",
            "[7200/20000] Loss: 1.267889 Time: 42.7s\n",
            "[7300/20000] Loss: 1.193572 Time: 43.2s\n",
            "[7400/20000] Loss: 1.276319 Time: 43.7s\n",
            "[7500/20000] Loss: 1.251292 Time: 44.2s\n",
            "[7600/20000] Loss: 1.248389 Time: 44.7s\n",
            "[7700/20000] Loss: 1.236654 Time: 45.2s\n",
            "[7800/20000] Loss: 1.209810 Time: 45.9s\n",
            "[7900/20000] Loss: 1.238595 Time: 46.5s\n",
            "[8000/20000] Loss: 1.219609 Time: 47.2s\n",
            "[8100/20000] Loss: 1.245433 Time: 47.7s\n",
            "[8200/20000] Loss: 1.219828 Time: 48.2s\n",
            "[8300/20000] Loss: 1.205814 Time: 48.7s\n",
            "[8400/20000] Loss: 1.231649 Time: 49.2s\n",
            "[8500/20000] Loss: 1.214798 Time: 49.7s\n",
            "[8600/20000] Loss: 1.222873 Time: 50.5s\n",
            "[8700/20000] Loss: 1.252989 Time: 51.0s\n",
            "[8800/20000] Loss: 1.222749 Time: 51.5s\n",
            "[8900/20000] Loss: 1.234063 Time: 52.0s\n",
            "[9000/20000] Loss: 1.213999 Time: 52.5s\n",
            "[9100/20000] Loss: 1.250653 Time: 53.0s\n",
            "[9200/20000] Loss: 1.207202 Time: 53.5s\n",
            "[9300/20000] Loss: 1.212428 Time: 54.0s\n",
            "[9400/20000] Loss: 1.236963 Time: 54.5s\n",
            "[9500/20000] Loss: 1.187401 Time: 55.0s\n",
            "[9600/20000] Loss: 1.233915 Time: 55.8s\n",
            "[9700/20000] Loss: 1.228451 Time: 57.0s\n",
            "[9800/20000] Loss: 1.183522 Time: 57.7s\n",
            "[9900/20000] Loss: 1.246012 Time: 58.4s\n",
            "[10000/20000] Loss: 1.238669 Time: 59.6s\n",
            "[10100/20000] Loss: 1.222208 Time: 60.1s\n",
            "[10200/20000] Loss: 1.209520 Time: 60.7s\n",
            "[10300/20000] Loss: 1.244029 Time: 61.3s\n",
            "[10400/20000] Loss: 1.209105 Time: 62.2s\n",
            "[10500/20000] Loss: 1.247706 Time: 62.8s\n",
            "[10600/20000] Loss: 1.239655 Time: 63.4s\n",
            "[10700/20000] Loss: 1.197616 Time: 64.0s\n",
            "[10800/20000] Loss: 1.210526 Time: 64.7s\n",
            "[10900/20000] Loss: 1.227369 Time: 65.3s\n",
            "[11000/20000] Loss: 1.238597 Time: 66.0s\n",
            "[11100/20000] Loss: 1.194100 Time: 66.5s\n",
            "[11200/20000] Loss: 1.239876 Time: 67.0s\n",
            "[11300/20000] Loss: 1.198400 Time: 67.5s\n",
            "[11400/20000] Loss: 1.268906 Time: 68.4s\n",
            "[11500/20000] Loss: 1.243070 Time: 68.9s\n",
            "[11600/20000] Loss: 1.205375 Time: 69.5s\n",
            "[11700/20000] Loss: 1.227332 Time: 70.1s\n",
            "[11800/20000] Loss: 1.223044 Time: 70.7s\n",
            "[11900/20000] Loss: 1.217785 Time: 71.5s\n",
            "[12000/20000] Loss: 1.173700 Time: 72.1s\n",
            "[12100/20000] Loss: 1.209884 Time: 72.7s\n",
            "[12200/20000] Loss: 1.196591 Time: 73.2s\n",
            "[12300/20000] Loss: 1.208332 Time: 73.9s\n",
            "[12400/20000] Loss: 1.222396 Time: 74.7s\n",
            "[12500/20000] Loss: 1.222945 Time: 75.3s\n",
            "[12600/20000] Loss: 1.242554 Time: 75.9s\n",
            "[12700/20000] Loss: 1.257058 Time: 76.5s\n",
            "[12800/20000] Loss: 1.237447 Time: 77.0s\n",
            "[12900/20000] Loss: 1.207253 Time: 77.7s\n",
            "[13000/20000] Loss: 1.232871 Time: 78.4s\n",
            "[13100/20000] Loss: 1.213458 Time: 78.9s\n",
            "[13200/20000] Loss: 1.238634 Time: 79.6s\n",
            "[13300/20000] Loss: 1.211971 Time: 80.2s\n",
            "[13400/20000] Loss: 1.210970 Time: 80.7s\n",
            "[13500/20000] Loss: 1.243184 Time: 81.3s\n",
            "[13600/20000] Loss: 1.238523 Time: 81.9s\n",
            "[13700/20000] Loss: 1.237325 Time: 82.7s\n",
            "[13800/20000] Loss: 1.227876 Time: 83.6s\n",
            "[13900/20000] Loss: 1.205669 Time: 84.2s\n",
            "[14000/20000] Loss: 1.246268 Time: 84.8s\n",
            "[14100/20000] Loss: 1.234146 Time: 85.4s\n",
            "[14200/20000] Loss: 1.242173 Time: 86.1s\n",
            "[14300/20000] Loss: 1.241057 Time: 86.7s\n",
            "[14400/20000] Loss: 1.170220 Time: 87.1s\n",
            "[14500/20000] Loss: 1.227847 Time: 87.7s\n",
            "[14600/20000] Loss: 1.224752 Time: 88.2s\n",
            "[14700/20000] Loss: 1.201996 Time: 88.7s\n",
            "[14800/20000] Loss: 1.220294 Time: 89.2s\n",
            "[14900/20000] Loss: 1.193527 Time: 89.7s\n",
            "[15000/20000] Loss: 1.228305 Time: 90.4s\n",
            "[15100/20000] Loss: 1.197945 Time: 91.0s\n",
            "[15200/20000] Loss: 1.214234 Time: 91.5s\n",
            "[15300/20000] Loss: 1.195331 Time: 92.0s\n",
            "[15400/20000] Loss: 1.249277 Time: 92.6s\n",
            "[15500/20000] Loss: 1.228894 Time: 93.2s\n",
            "[15600/20000] Loss: 1.240021 Time: 93.7s\n",
            "[15700/20000] Loss: 1.204771 Time: 94.4s\n",
            "[15800/20000] Loss: 1.216492 Time: 95.5s\n",
            "[15900/20000] Loss: 1.215760 Time: 96.1s\n",
            "[16000/20000] Loss: 1.213177 Time: 96.6s\n",
            "[16100/20000] Loss: 1.210774 Time: 97.1s\n",
            "[16200/20000] Loss: 1.190554 Time: 97.6s\n",
            "[16300/20000] Loss: 1.206987 Time: 98.1s\n",
            "[16400/20000] Loss: 1.201743 Time: 98.6s\n",
            "[16500/20000] Loss: 1.242911 Time: 99.1s\n",
            "[16600/20000] Loss: 1.227807 Time: 99.6s\n",
            "[16700/20000] Loss: 1.173610 Time: 100.1s\n",
            "[16800/20000] Loss: 1.182485 Time: 100.6s\n",
            "[16900/20000] Loss: 1.247313 Time: 101.1s\n",
            "[17000/20000] Loss: 1.211255 Time: 101.6s\n",
            "[17100/20000] Loss: 1.204099 Time: 102.1s\n",
            "[17200/20000] Loss: 1.248097 Time: 102.6s\n",
            "[17300/20000] Loss: 1.198491 Time: 103.1s\n",
            "[17400/20000] Loss: 1.205817 Time: 103.6s\n",
            "[17500/20000] Loss: 1.211735 Time: 104.1s\n",
            "[17600/20000] Loss: 1.246833 Time: 104.6s\n",
            "[17700/20000] Loss: 1.264373 Time: 105.2s\n",
            "[17800/20000] Loss: 1.229918 Time: 105.7s\n",
            "[17900/20000] Loss: 1.192104 Time: 106.3s\n",
            "[18000/20000] Loss: 1.197742 Time: 106.9s\n",
            "[18100/20000] Loss: 1.212293 Time: 107.6s\n",
            "[18200/20000] Loss: 1.195806 Time: 108.2s\n",
            "[18300/20000] Loss: 1.234428 Time: 108.7s\n",
            "[18400/20000] Loss: 1.238590 Time: 109.2s\n",
            "[18500/20000] Loss: 1.197754 Time: 109.7s\n",
            "[18600/20000] Loss: 1.208753 Time: 110.2s\n",
            "[18700/20000] Loss: 1.199078 Time: 110.7s\n",
            "[18800/20000] Loss: 1.219422 Time: 111.2s\n",
            "[18900/20000] Loss: 1.219060 Time: 111.7s\n",
            "[19000/20000] Loss: 1.205115 Time: 112.2s\n",
            "[19100/20000] Loss: 1.259423 Time: 112.7s\n",
            "[19200/20000] Loss: 1.222700 Time: 113.2s\n",
            "[19300/20000] Loss: 1.226976 Time: 113.7s\n",
            "[19400/20000] Loss: 1.194992 Time: 114.3s\n",
            "[19500/20000] Loss: 1.191550 Time: 114.8s\n",
            "[19600/20000] Loss: 1.221004 Time: 115.3s\n",
            "[19700/20000] Loss: 1.226230 Time: 115.8s\n",
            "[19800/20000] Loss: 1.243746 Time: 116.3s\n",
            "[19900/20000] Loss: 1.231866 Time: 116.8s\n",
            "[20000/20000] Loss: 1.204944 Time: 117.3s\n",
            "âœ… Stage1 training completed! Final loss: 1.204944\n",
            "Total training time: 117.3 seconds\n"
          ]
        }
      ],
      "source": [
        "# Execute Stage1 training\n",
        "# the result will be flollowing : At first, it drops down dramatically , then it fluctuates.\n",
        "import random\n",
        "import time\n",
        "from torch import optim\n",
        "\n",
        "# Set random seeds\n",
        "random.seed(stage1_config['seed'])\n",
        "torch.manual_seed(stage1_config['seed'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(stage1_config['seed'])\n",
        "\n",
        "# Create flow model\n",
        "flow = BundleFlow(m=stage1_config['m']).to(device)\n",
        "optimizer = optim.Adam(flow.parameters(), lr=stage1_config['lr'])\n",
        "\n",
        "# Initial distribution (mixture of Gaussians)\n",
        "mus = torch.empty(stage1_config['D'], stage1_config['m'], device=device).uniform_(-0.2, 1.2)\n",
        "sigmas = torch.full((stage1_config['D'],), 0.5, device=device)\n",
        "weights = torch.full((stage1_config['D'],), 1.0 / stage1_config['D'], device=device)\n",
        "\n",
        "print(f\"Stage1 training started (device: {device})\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in flow.parameters()):,}\")\n",
        "\n",
        "# Training loop\n",
        "losses = []\n",
        "start_time = time.time()\n",
        "\n",
        "for it in range(1, stage1_config['iters'] + 1):\n",
        "    # Calculate Rectified Flow loss\n",
        "    loss = flow.rectified_flow_loss(\n",
        "        B=stage1_config['batch'],\n",
        "        mus=mus, sigmas=sigmas, weights=weights,\n",
        "        sigma_z=stage1_config['sigma_z']\n",
        "    )\n",
        "\n",
        "    # Optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.detach().item())\n",
        "\n",
        "    # Progress display\n",
        "    if it % 100 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"[{it}/{stage1_config['iters']}] Loss: {loss.detach().item():.6f} Time: {elapsed:.1f}s\")\n",
        "\n",
        "print(f\"âœ… Stage1 training completed! Final loss: {losses[-1]:.6f}\")\n",
        "print(f\"Total training time: {time.time() - start_time:.1f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "xBIxylZQZO2w",
        "outputId": "508ea9b4-0323-4cc4-d3fb-00c278d930c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated bundle diversity: 0.078 (80/1024 unique bundles)\n"
          ]
        }
      ],
      "source": [
        "# Stage1 results visualization\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Loss progression\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses)\n",
        "plt.title('Stage1: Rectified Flow Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.yscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Bundle generation test\n",
        "plt.subplot(1, 2, 2)\n",
        "with torch.no_grad():\n",
        "    # Generate bundles from random initial values\n",
        "    z = torch.randn(100, stage1_config['m'], device=device)\n",
        "    t_grid = torch.linspace(0.0, 1.0, steps=stage1_config['ode_steps'], device=device)\n",
        "    x_T = flow.flow_forward(z, t_grid)\n",
        "    bundles = flow.round_to_bundle(x_T)\n",
        "\n",
        "    # Calculate bundle diversity\n",
        "    unique_bundles = torch.unique(bundles, dim=0)\n",
        "    diversity = len(unique_bundles) / (2 ** stage1_config['m'])\n",
        "\n",
        "    # Visualize bundle distribution\n",
        "    bundle_sizes = bundles.sum(dim=1).detach().cpu().numpy()\n",
        "    plt.hist(bundle_sizes, bins=range(stage1_config['m']+2), alpha=0.7, edgecolor='black')\n",
        "    plt.title(f'Bundle Size Distribution\\\\nDiversity: {diversity:.3f}')\n",
        "    plt.xlabel('Bundle Size')\n",
        "    plt.ylabel('Count')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Generated bundle diversity: {diversity:.3f} ({len(unique_bundles)}/{2**stage1_config['m']} unique bundles)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHMX2hn1ZO2w",
        "outputId": "f5434e99-5092-42d8-9446-1e767b0aadda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GPUç›£è¦–ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\n"
          ]
        }
      ],
      "source": [
        "# === GPU Monitoring Helper Functions ============================================\n",
        "import inspect\n",
        "\n",
        "CANDIDATE_ATTRS = [\"as_tensor\", \"to_tensor\", \"tensor\",\n",
        "                   \"x\", \"vec\", \"features\", \"data\", \"value_vec\", \"params\"]\n",
        "\n",
        "def extract_feature_like(v):\n",
        "    \"\"\"\n",
        "    Extract \"feature vector\" from Valuation object v.\n",
        "    - Call zero-argument methods (as_tensor/to_tensor etc.).\n",
        "    - Skip methods that require arguments (value(s_bool) etc.).\n",
        "    - Search for typical attribute names in order.\n",
        "    - For XORValuation, construct feature vector from atoms.\n",
        "    \"\"\"\n",
        "    # XORValuationã®ç‰¹åˆ¥å‡¦ç†\n",
        "    if hasattr(v, 'atoms') and hasattr(v, 'm'):\n",
        "        # XORValuationã®å ´åˆï¼šatomsã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰\n",
        "        m = v.m\n",
        "        feature_vec = torch.zeros(m, dtype=torch.float32)\n",
        "\n",
        "        # å„atomã®ä¾¡æ ¼ã‚’å¯¾å¿œã™ã‚‹å•†å“ä½ç½®ã«åŠ ç®—\n",
        "        for mask, price in v.atoms:\n",
        "            for i in range(m):\n",
        "                if mask & (1 << i):  # ãƒ“ãƒƒãƒˆiãŒç«‹ã£ã¦ã„ã‚‹å ´åˆ\n",
        "                    feature_vec[i] += price\n",
        "\n",
        "        return feature_vec\n",
        "\n",
        "    # ç„¡å¼•æ•°ãƒ¡ã‚½ãƒƒãƒ‰å€™è£œ\n",
        "    for name in [\"as_tensor\", \"to_tensor\"]:\n",
        "        if hasattr(v, name) and callable(getattr(v, name)):\n",
        "            fn = getattr(v, name)\n",
        "            try:\n",
        "                sig = inspect.signature(fn)\n",
        "                if len([p for p in sig.parameters.values()\n",
        "                        if p.default is p.empty and p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD)]) == 0:\n",
        "                    return fn()  # ç„¡å¼•æ•°ãªã‚‰å‘¼ã³å‡ºã—\n",
        "            except (ValueError, TypeError):\n",
        "                # signatureãŒå–ã‚Œãªã„å ´åˆã¯å‘¼ã‚“ã§ã¿ã‚‹\n",
        "                try:\n",
        "                    return fn()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    # å±žæ€§å€™è£œ\n",
        "    for name in [\"tensor\", \"x\", \"vec\", \"features\", \"data\", \"value_vec\", \"params\"]:\n",
        "        if hasattr(v, name):\n",
        "            return getattr(v, name)\n",
        "\n",
        "    # ãƒ‡ãƒãƒƒã‚°ç”¨ã®æƒ…å ±ã‚’æŠ•ã’ã‚‹\n",
        "    public = [a for a in dir(v) if not a.startswith(\"_\")]\n",
        "    raise TypeError(\n",
        "        \"Could not extract feature vector from valuation.\\n\"\n",
        "        f\"type={type(v)}\\n\"\n",
        "        f\"public={public}\\n\"\n",
        "        \"â†’ v.x / v.vec / v.features ç­‰ã®å±žæ€§åã‚’CANDIDATE_ATTRSã¸è¿½åŠ ã™ã‚‹ã“ã¨ã€‚\"\n",
        "    )\n",
        "\n",
        "def to_tensor_1d(x, device):\n",
        "    if torch.is_tensor(x):\n",
        "        t = x\n",
        "    elif isinstance(x, (list, tuple)):\n",
        "        t = torch.tensor(x)\n",
        "    elif isinstance(x, (int, float)):\n",
        "        t = torch.tensor([x])\n",
        "    else:\n",
        "        try:\n",
        "            t = torch.as_tensor(x)\n",
        "        except Exception as e:\n",
        "            raise TypeError(f\"Unsupported feature payload: {type(x)}; err={e}\")\n",
        "    return t.to(device=device, dtype=torch.float32, non_blocking=True).flatten()\n",
        "\n",
        "def batch_to_tensor(batch_list, device):\n",
        "    vecs = []\n",
        "    for v in batch_list:\n",
        "        raw = extract_feature_like(v)\n",
        "        vecs.append(to_tensor_1d(raw, device))\n",
        "    # é•·ã•ãƒã‚§ãƒƒã‚¯\n",
        "    dims = {t.numel() for t in vecs}\n",
        "    if len(dims) != 1:\n",
        "        raise ValueError(f\"Feature length mismatch across batch: {sorted(dims)}\")\n",
        "    return torch.stack(vecs, dim=0)  # [B, D]\n",
        "\n",
        "print(\"âœ… Define GPU Monitoring Helper Functions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roaMfRvrZO2w"
      },
      "source": [
        "## 4. Stage2: Menu Optimization\n",
        "\n",
        "Use the trained velocity field to optimize menu elements (prices and initial distributions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojNny582ZO2x",
        "outputId": "9d6ee88e-2e42-4038-9800-2490730cc69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Generated 100 valuation functions\n",
            "Number of atoms in first valuation: 10\n",
            "Atom count statistics: min=10, max=10, mean=10.0\n"
          ]
        }
      ],
      "source": [
        "# Generate valuation function data\n",
        "from bundleflow.data import gen_uniform_iid_xor\n",
        "\n",
        "# Set random seeds\n",
        "random.seed(stage2_config['seed'])\n",
        "torch.manual_seed(stage2_config['seed'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(stage2_config['seed'])\n",
        "\n",
        "# Generate synthetic XOR valuation functions\n",
        "valuations = []\n",
        "for i in range(stage2_config['n_val']):\n",
        "    val = gen_uniform_iid_xor(\n",
        "        m=stage1_config['m'],\n",
        "        a=stage2_config['a'],\n",
        "        low=0.0,\n",
        "        high=1.0,\n",
        "        seed=1337 + i,\n",
        "        atom_size_mode='small'\n",
        "    )\n",
        "    valuations.append(val)\n",
        "\n",
        "print(f\"âœ… Generated {len(valuations)} valuation functions\")\n",
        "print(f\"Number of atoms in first valuation: {len(valuations[0].atoms)}\")\n",
        "\n",
        "# Valuation function statistics\n",
        "atom_counts = [len(v.atoms) for v in valuations]\n",
        "print(f\"Atom count statistics: min={min(atom_counts)}, max={max(atom_counts)}, mean={np.mean(atom_counts):.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay8mhVkHeltI",
        "outputId": "ed360973-0d94-45f5-f666-1ee64de783f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BundleFlow modules imported successfully\n",
            "ðŸš€ Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.8 GB\n",
            "ðŸŽ¯ GPU Optimization Configuration:\n",
            "  m: 10\n",
            "  K: 16\n",
            "  D: 4\n",
            "  iters: 10000\n",
            "  batch: 64\n",
            "  lr: 0.001\n",
            "  lam_start: 0.5\n",
            "  lam_end: 0.1\n",
            "  ode_steps: 25\n",
            "  n_val: 200\n",
            "  a: 32\n",
            "  seed: 42\n",
            "  grad_clip: 1.0\n",
            "  use_gumbel: False\n",
            "  tau_start: 1.0\n",
            "  tau_end: 0.01\n"
          ]
        }
      ],
      "source": [
        "# ðŸš€ GPU-optimized version: Perfect Stage2 training processing entirely on GPU (revised)\n",
        "# Completely eliminate CPU-GPU transfers and complete all computations on GPU\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "\n",
        "# Check existing imports and models\n",
        "try:\n",
        "    from bundleflow.models.flow import BundleFlow\n",
        "    from bundleflow.models.menu import MenuElement, make_null_element\n",
        "    from bundleflow.valuation.valuation import XORValuation\n",
        "    from bundleflow.data import gen_uniform_iid_xor\n",
        "    print(\"âœ… BundleFlow modules imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import error: {e}\")\n",
        "    print(\"Please make sure you're in the correct directory and have run the previous cells\")\n",
        "\n",
        "# Check and configure GPU environment\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ðŸš€ Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    torch.cuda.empty_cache()  # Clear GPU memory\n",
        "else:\n",
        "    print(\"âš ï¸  GPU not available, using CPU\")\n",
        "\n",
        "# GPU optimization configuration\n",
        "gpu_config = {\n",
        "    'K': 64,           # Number of menu elements (significantly increased for more items)\n",
        "    'D': 8,            # Number of mixture components for initial distribution (more diverse)\n",
        "    'iters': 5000,    # Number of iterations (significantly increased)\n",
        "    'batch': 64,      # Batch size (increased for more items)\n",
        "    'lr': 2e-4,        # Learning rate (stable learning)\n",
        "    'lam_start': 0.5,  # SoftMax temperature start value (high temperature for exploration)\n",
        "    'lam_end': 0.1,    # SoftMax temperature end value (low temperature for decision)\n",
        "    'ode_steps': 50,   # ODE integration steps (high precision)\n",
        "    'n_val': 100,     # Number of valuation functions (improved statistical reliability)\n",
        "    'a': 10,          # XOR atoms (significantly increased for more items)\n",
        "    'seed': 42,\n",
        "    'warmup_iters': 500,  # Î² warmup period\n",
        "    'freeze_beta_iters': 1000,  # Î² freeze period\n",
        "    'grad_clip': 1.0,  # Gradient clipping\n",
        "    'use_gumbel': True,  # Use Gumbel-Softmax\n",
        "    'tau_start': 1.0,  # Gumbel temperature start value\n",
        "    'tau_end': 0.01    # Gumbel temperature end value\n",
        "}\n",
        "\n",
        "print(\"ðŸŽ¯ GPU Optimization Configuration:\")\n",
        "for key, value in gpu_config.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(gpu_config['seed'])\n",
        "np.random.seed(gpu_config['seed'])\n",
        "random.seed(gpu_config['seed'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(gpu_config['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ GPUå°‚ç”¨å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆÎ²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‡çµåˆ¶å¾¡ä»˜ãï¼‰\n",
        "def run_gpu_optimized_training_with_beta_freeze():\n",
        "    \"\"\"\n",
        "    GPUå°‚ç”¨æœ€é©åŒ–å­¦ç¿’ï¼ˆÎ²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‡çµåˆ¶å¾¡ä»˜ãï¼‰\n",
        "    - æ—¢å­˜ã®flowãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨\n",
        "    - Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ®µéšŽçš„å‡çµè§£é™¤\n",
        "    - å…¨è¨ˆç®—ã‚’GPUä¸Šã§å®Œçµ\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"ðŸš€ GPUå°‚ç”¨æœ€é©åŒ–å­¦ç¿’é–‹å§‹ï¼ˆÎ²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‡çµåˆ¶å¾¡ä»˜ãï¼‰\")\n",
        "\n",
        "    # æ—¢å­˜ã®flowãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª\n",
        "    try:\n",
        "        if 'flow' not in globals():\n",
        "            print(\"âŒ flowãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Stage1ã®å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "            return None, None\n",
        "\n",
        "        # ãƒ•ãƒ­ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’GPUã«ç§»å‹•\n",
        "        flow_gpu = flow.to(device)\n",
        "        flow_gpu.eval()\n",
        "        for p in flow_gpu.parameters():\n",
        "            p.requires_grad_(False)\n",
        "        print(f\"âœ… Flow model moved to {device}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Flow model error: {e}\")\n",
        "        print(\"å…ˆã«Stage1ã®å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦flowãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")\n",
        "        return None, None\n",
        "\n",
        "    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¦ç´ ã‚’GPUä¸Šã§ä½œæˆ\n",
        "    menu = []\n",
        "    for _ in range(gpu_config['K']):\n",
        "        elem = MenuElement(m=gpu_config['m'], D=gpu_config['D'])\n",
        "        elem = elem.to(device)\n",
        "        menu.append(elem)\n",
        "\n",
        "    # nullè¦ç´ ã‚‚GPUä¸Šã§ä½œæˆ\n",
        "    null_elem = make_null_element(gpu_config['m']).to(device)\n",
        "    menu.append(null_elem)\n",
        "\n",
        "    # è©•ä¾¡é–¢æ•°ã‚’æ­£ã—ã„æ–¹æ³•ã§ä½œæˆ\n",
        "    V = []\n",
        "    print(f\"ðŸ“Š Creating {gpu_config['n_val']} XOR valuations...\")\n",
        "    for i in range(gpu_config['n_val']):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"  Creating valuation {i+1}/{gpu_config['n_val']}\")\n",
        "        v = gen_uniform_iid_xor(\n",
        "            m=gpu_config['m'],\n",
        "            a=gpu_config['a'],\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            seed=gpu_config['seed'] + i,\n",
        "            atom_size_mode=\"small\"\n",
        "        )\n",
        "        V.append(v)\n",
        "\n",
        "    print(f\"âœ… GPUä¸Šã«ä½œæˆå®Œäº†: {len(menu)} menu elements, {len(V)} valuations\")\n",
        "\n",
        "    # Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‡çµåˆ¶å¾¡è¨­å®š\n",
        "    freeze_beta_iters = 1000  # Î²ã‚’1000ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‡çµ\n",
        "    beta_unfrozen = False\n",
        "    \n",
        "    # åˆæœŸã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ãƒ¼ï¼ˆÎ¼ã¨wã®ã¿ï¼‰\n",
        "    mu_w_params = []\n",
        "    beta_params = []\n",
        "    \n",
        "    for elem in menu[:-1]:  # nullè¦ç´ ã¯é™¤å¤–\n",
        "        # Î¼ã¨wã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "        mu_w_params.extend([elem.mus, elem.logits])\n",
        "        # Î²ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "        beta_params.append(elem.beta_raw)\n",
        "    \n",
        "    # åˆæœŸã¯Î¼ã¨wã®ã¿æœ€é©åŒ–\n",
        "    optimizer = optim.Adam(mu_w_params, lr=gpu_config['lr'])\n",
        "    print(f\"ðŸš€ Initial optimizer: {len(mu_w_params)} parameters (Î¼/w only)\")\n",
        "\n",
        "    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "    revenues = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for it in range(1, gpu_config['iters'] + 1):\n",
        "        # Î²ã®å‡çµè§£é™¤ï¼ˆwarmupæœŸé–“å¾Œï¼‰\n",
        "        if not beta_unfrozen and it > freeze_beta_iters:\n",
        "            print(f\"\\n[Iteration {it}] Unfreezing Î² parameters...\")\n",
        "            all_params = mu_w_params + beta_params\n",
        "            optimizer = optim.Adam(all_params, lr=gpu_config['lr'])\n",
        "            beta_unfrozen = True\n",
        "            print(f\"[Iteration {it}] Now optimizing {len(all_params)} parameters (Î¼/w/Î²)\")\n",
        "\n",
        "        # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
        "        batch_size = min(gpu_config['batch'], len(V))\n",
        "        batch_V = random.sample(V, batch_size)\n",
        "\n",
        "        # æ¸©åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¯¾å¿œï¼‰\n",
        "        warmup_iters = 500\n",
        "        if it <= warmup_iters:\n",
        "            # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ï¼šä½Žã„Î»ã§æŽ¢ç´¢\n",
        "            lam = gpu_config['lam_start'] * (it / warmup_iters)\n",
        "        else:\n",
        "            # é€šå¸¸æœŸé–“ï¼šÎ»ã‚’lam_endã¸\n",
        "            progress = (it - warmup_iters) / (gpu_config['iters'] - warmup_iters)\n",
        "            lam = gpu_config['lam_start'] + (gpu_config['lam_end'] - gpu_config['lam_start']) * progress\n",
        "\n",
        "        # æ™‚é–“ã‚°ãƒªãƒƒãƒ‰ã‚’GPUä¸Šã§ä½œæˆ\n",
        "        t_grid = torch.linspace(0.0, 1.0, steps=gpu_config['ode_steps'], device=device)\n",
        "\n",
        "        # GPUå°‚ç”¨åŽç›Šæå¤±è¨ˆç®—ï¼ˆIRåˆ¶ç´„ä»˜ãï¼‰\n",
        "        loss = gpu_revenue_loss_with_ir(flow_gpu, batch_V, menu, t_grid, lam=lam, verbose=(it % 100 == 0))\n",
        "\n",
        "        # æœ€é©åŒ–ï¼ˆGPUä¸Šã§å®Œçµï¼‰\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(all_params if beta_unfrozen else mu_w_params, gpu_config['grad_clip'])\n",
        "        optimizer.step()\n",
        "\n",
        "        # åŽç›Šè¨˜éŒ²\n",
        "        revenues.append(-loss.detach().item())\n",
        "\n",
        "        # é€²æ—è¡¨ç¤ºï¼ˆGPUç›£è¦–ä»˜ãï¼‰\n",
        "        if it % 50 == 0:\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "                mem_alloc = torch.cuda.memory_allocated() / 1024**2\n",
        "                mem_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "                mem_str = f\" | GPU mem: {mem_alloc:.0f}/{mem_reserved:.0f}MB\"\n",
        "            else:\n",
        "                mem_str = \"\"\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            beta_status = \"Î² unfrozen\" if beta_unfrozen else \"Î² frozen\"\n",
        "            print(f\"[{it}/{gpu_config['iters']}] Revenue: {revenues[-1]:.6f} Î»:{lam:.4f} {beta_status} Time:{elapsed:.1f}s{mem_str}\")\n",
        "\n",
        "    print(f\"âœ… GPUå°‚ç”¨å­¦ç¿’å®Œäº†! æœ€çµ‚åŽç›Š: {revenues[-1]:.6f}\")\n",
        "    print(f\"ç·å­¦ç¿’æ™‚é–“: {time.time() - start_time:.1f}ç§’\")\n",
        "\n",
        "    return revenues, menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPUå°‚ç”¨åŽç›Šæå¤±é–¢æ•°ï¼ˆIRåˆ¶ç´„ä»˜ãï¼‰\n",
        "def gpu_revenue_loss_with_ir(flow, V, menu, t_grid, lam=0.1, verbose=False):\n",
        "    \"\"\"\n",
        "    GPUå°‚ç”¨åŽç›Šæå¤±è¨ˆç®—ï¼ˆIRåˆ¶ç´„ä»˜ãï¼‰\n",
        "    - IRåˆ¶ç´„ã®æ˜Žç¤ºçš„é©ç”¨\n",
        "    - åˆ¶ç´„é•åæ™‚ã¯åŽç›Šã‚¼ãƒ­\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"  [GPU-Optimized-IR] Computing utilities matrix on {t_grid.device}\")\n",
        "\n",
        "    U = gpu_utilities_matrix_optimized(flow, V, menu, t_grid, verbose=verbose)\n",
        "    beta = torch.stack([elem.beta for elem in menu]).squeeze()\n",
        "\n",
        "    # Softmaxå‰²å½“\n",
        "    Z = torch.softmax(lam * U, dim=1)  # (B, K)\n",
        "    \n",
        "    # IRåˆ¶ç´„ã®æ˜Žç¤ºçš„é©ç”¨\n",
        "    # å„è©•ä¾¡é–¢æ•°ã«ã¤ã„ã¦ã€é¸æŠžã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼è¦ç´ ã®åŠ¹ç”¨ã‚’ãƒã‚§ãƒƒã‚¯\n",
        "    selected_idx = torch.argmax(Z, dim=1)  # (B,) - å„è©•ä¾¡é–¢æ•°ãŒé¸æŠžã—ãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼è¦ç´ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
        "    selected_utility = torch.gather(U, 1, selected_idx.unsqueeze(1)).squeeze(1)  # (B,) - é¸æŠžã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®åŠ¹ç”¨\n",
        "    \n",
        "    # IRåˆ¶ç´„: åŠ¹ç”¨ãŒè² ã®å ´åˆã¯åŽç›Šã‚¼ãƒ­\n",
        "    ir_mask = (selected_utility >= 0.0).float()  # (B,) - IRåˆ¶ç´„ã‚’æº€ãŸã™ã‹ã©ã†ã‹ã®ãƒžã‚¹ã‚¯\n",
        "    \n",
        "    # åŽç›Šè¨ˆç®—: IRåˆ¶ç´„ã‚’æº€ãŸã•ãªã„å ´åˆã¯0\n",
        "    rev_per_buyer = (Z * beta.unsqueeze(0)).sum(dim=1) * ir_mask  # (B,)\n",
        "    rev = rev_per_buyer.mean()\n",
        "\n",
        "    if verbose:\n",
        "        ir_satisfaction_rate = ir_mask.mean().item()\n",
        "        print(f\"  [GPU-Optimized-IR] Revenue: {rev.item():.6f}, IR satisfaction: {ir_satisfaction_rate:.3f}\")\n",
        "\n",
        "    return -rev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ ä¿®æ­£ç‰ˆGPUå°‚ç”¨å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆÎ²å‡çµåˆ¶å¾¡ + IRåˆ¶ç´„ä»˜ãï¼‰\n",
        "def run_corrected_gpu_training():\n",
        "    \"\"\"\n",
        "    ä¿®æ­£ç‰ˆGPUå°‚ç”¨æœ€é©åŒ–å­¦ç¿’\n",
        "    - Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ®µéšŽçš„å‡çµè§£é™¤\n",
        "    - IRåˆ¶ç´„ã®æ˜Žç¤ºçš„é©ç”¨\n",
        "    - ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æœŸé–“ä»˜ãæ¸©åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"ðŸš€ ä¿®æ­£ç‰ˆGPUå°‚ç”¨æœ€é©åŒ–å­¦ç¿’é–‹å§‹\")\n",
        "\n",
        "    # æ—¢å­˜ã®flowãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª\n",
        "    try:\n",
        "        if 'flow' not in globals():\n",
        "            print(\"âŒ flowãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Stage1ã®å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "            return None, None\n",
        "\n",
        "        flow_gpu = flow.to(device)\n",
        "        flow_gpu.eval()\n",
        "        for p in flow_gpu.parameters():\n",
        "            p.requires_grad_(False)\n",
        "        print(f\"âœ… Flow model moved to {device}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Flow model error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¦ç´ ã‚’GPUä¸Šã§ä½œæˆ\n",
        "    menu = []\n",
        "    for _ in range(gpu_config['K']):\n",
        "        elem = MenuElement(m=gpu_config['m'], D=gpu_config['D'])\n",
        "        elem = elem.to(device)\n",
        "        menu.append(elem)\n",
        "\n",
        "    # nullè¦ç´ ã‚‚GPUä¸Šã§ä½œæˆ\n",
        "    null_elem = make_null_element(gpu_config['m']).to(device)\n",
        "    menu.append(null_elem)\n",
        "\n",
        "    # è©•ä¾¡é–¢æ•°ã‚’æ­£ã—ã„æ–¹æ³•ã§ä½œæˆ\n",
        "    V = []\n",
        "    print(f\"ðŸ“Š Creating {gpu_config['n_val']} XOR valuations...\")\n",
        "    for i in range(gpu_config['n_val']):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"  Creating valuation {i+1}/{gpu_config['n_val']}\")\n",
        "        v = gen_uniform_iid_xor(\n",
        "            m=gpu_config['m'],\n",
        "            a=gpu_config['a'],\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            seed=gpu_config['seed'] + i,\n",
        "            atom_size_mode=\"small\"\n",
        "        )\n",
        "        V.append(v)\n",
        "\n",
        "    print(f\"âœ… GPUä¸Šã«ä½œæˆå®Œäº†: {len(menu)} menu elements, {len(V)} valuations\")\n",
        "\n",
        "    # Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‡çµåˆ¶å¾¡è¨­å®š\n",
        "    freeze_beta_iters = 1000  # Î²ã‚’1000ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‡çµ\n",
        "    beta_unfrozen = False\n",
        "    \n",
        "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ†é›¢\n",
        "    mu_w_params = []\n",
        "    beta_params = []\n",
        "    \n",
        "    for elem in menu[:-1]:  # nullè¦ç´ ã¯é™¤å¤–\n",
        "        mu_w_params.extend([elem.mus, elem.logits])\n",
        "        beta_params.append(elem.beta_raw)\n",
        "    \n",
        "    # åˆæœŸã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ãƒ¼ï¼ˆÎ¼ã¨wã®ã¿ï¼‰\n",
        "    optimizer = optim.Adam(mu_w_params, lr=gpu_config['lr'])\n",
        "    print(f\"ðŸš€ Initial optimizer: {len(mu_w_params)} parameters (Î¼/w only)\")\n",
        "\n",
        "    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "    revenues = []\n",
        "    ir_satisfaction_rates = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for it in range(1, gpu_config['iters'] + 1):\n",
        "        # Î²ã®å‡çµè§£é™¤ï¼ˆwarmupæœŸé–“å¾Œï¼‰\n",
        "        if not beta_unfrozen and it > freeze_beta_iters:\n",
        "            print(f\"\\n[Iteration {it}] Unfreezing Î² parameters...\")\n",
        "            all_params = mu_w_params + beta_params\n",
        "            optimizer = optim.Adam(all_params, lr=gpu_config['lr'])\n",
        "            beta_unfrozen = True\n",
        "            print(f\"[Iteration {it}] Now optimizing {len(all_params)} parameters (Î¼/w/Î²)\")\n",
        "\n",
        "        # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
        "        batch_size = min(gpu_config['batch'], len(V))\n",
        "        batch_V = random.sample(V, batch_size)\n",
        "\n",
        "        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¯¾å¿œã®æ¸©åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°\n",
        "        warmup_iters = 500\n",
        "        if it <= warmup_iters:\n",
        "            lam = gpu_config['lam_start'] * (it / warmup_iters)\n",
        "        else:\n",
        "            progress = (it - warmup_iters) / (gpu_config['iters'] - warmup_iters)\n",
        "            lam = gpu_config['lam_start'] + (gpu_config['lam_end'] - gpu_config['lam_start']) * progress\n",
        "\n",
        "        # æ™‚é–“ã‚°ãƒªãƒƒãƒ‰ã‚’GPUä¸Šã§ä½œæˆ\n",
        "        t_grid = torch.linspace(0.0, 1.0, steps=gpu_config['ode_steps'], device=device)\n",
        "\n",
        "        # GPUå°‚ç”¨åŽç›Šæå¤±è¨ˆç®—ï¼ˆIRåˆ¶ç´„ä»˜ãï¼‰\n",
        "        loss = gpu_revenue_loss_with_ir(flow_gpu, batch_V, menu, t_grid, lam=lam, verbose=(it % 100 == 0))\n",
        "\n",
        "        # æœ€é©åŒ–\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(all_params if beta_unfrozen else mu_w_params, gpu_config['grad_clip'])\n",
        "        optimizer.step()\n",
        "\n",
        "        # åŽç›Šè¨˜éŒ²\n",
        "        revenues.append(-loss.detach().item())\n",
        "\n",
        "        # IRåˆ¶ç´„æº€è¶³çŽ‡ã®è¨ˆç®—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰\n",
        "        with torch.no_grad():\n",
        "            U_debug = gpu_utilities_matrix_optimized(flow_gpu, batch_V[:10], menu, t_grid)  # ã‚µãƒ³ãƒ—ãƒ«ã§è¨ˆç®—\n",
        "            Z_debug = torch.softmax(lam * U_debug, dim=1)\n",
        "            selected_idx_debug = torch.argmax(Z_debug, dim=1)\n",
        "            selected_utility_debug = torch.gather(U_debug, 1, selected_idx_debug.unsqueeze(1)).squeeze(1)\n",
        "            ir_satisfaction_rate = (selected_utility_debug >= 0.0).float().mean().item()\n",
        "            ir_satisfaction_rates.append(ir_satisfaction_rate)\n",
        "\n",
        "        # é€²æ—è¡¨ç¤º\n",
        "        if it % 50 == 0:\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "                mem_alloc = torch.cuda.memory_allocated() / 1024**2\n",
        "                mem_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "                mem_str = f\" | GPU mem: {mem_alloc:.0f}/{mem_reserved:.0f}MB\"\n",
        "            else:\n",
        "                mem_str = \"\"\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            beta_status = \"Î² unfrozen\" if beta_unfrozen else \"Î² frozen\"\n",
        "            print(f\"[{it}/{gpu_config['iters']}] Revenue: {revenues[-1]:.6f} Î»:{lam:.4f} IR:{ir_satisfaction_rate:.3f} {beta_status} Time:{elapsed:.1f}s{mem_str}\")\n",
        "\n",
        "    print(f\"âœ… ä¿®æ­£ç‰ˆGPUå°‚ç”¨å­¦ç¿’å®Œäº†! æœ€çµ‚åŽç›Š: {revenues[-1]:.6f}\")\n",
        "    print(f\"æœ€çµ‚IRåˆ¶ç´„æº€è¶³çŽ‡: {ir_satisfaction_rates[-1]:.3f}\")\n",
        "    print(f\"ç·å­¦ç¿’æ™‚é–“: {time.time() - start_time:.1f}ç§’\")\n",
        "\n",
        "    return revenues, menu, ir_satisfaction_rates\n",
        "\n",
        "# ä¿®æ­£ç‰ˆå­¦ç¿’å®Ÿè¡Œ\n",
        "print(\"ðŸš€ ä¿®æ­£ç‰ˆGPUå°‚ç”¨æœ€é©åŒ–å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
        "revenues_corrected, menu_corrected, ir_rates = run_corrected_gpu_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXxvJ8OoZO2x"
      },
      "source": [
        "## 5. Results Visualization\n",
        "\n",
        "Visualize the training results to examine menu contents and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¿®æ­£ç‰ˆçµæžœã®å¯è¦–åŒ–\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. åŽç›Šã®æŽ¨ç§»\n",
        "axes[0, 0].plot(revenues_corrected)\n",
        "axes[0, 0].set_title('Revenue Progression (Corrected)')\n",
        "axes[0, 0].set_xlabel('Iteration')\n",
        "axes[0, 0].set_ylabel('Revenue')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. IRåˆ¶ç´„æº€è¶³çŽ‡ã®æŽ¨ç§»\n",
        "axes[0, 1].plot(ir_rates)\n",
        "axes[0, 1].set_title('IR Constraint Satisfaction Rate')\n",
        "axes[0, 1].set_xlabel('Iteration')\n",
        "axes[0, 1].set_ylabel('IR Satisfaction Rate')\n",
        "axes[0, 1].set_ylim(0, 1)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. ä¾¡æ ¼åˆ†å¸ƒ\n",
        "prices_corrected = [elem.price().detach().item() for elem in menu_corrected[:-1]]\n",
        "axes[1, 0].hist(prices_corrected, bins=20, alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_title('Price Distribution (Corrected)')\n",
        "axes[1, 0].set_xlabel('Price')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Î²ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŽ¨ç§»ï¼ˆå‡çµè§£é™¤ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¡¨ç¤ºï¼‰\n",
        "beta_values = [elem.beta_raw.detach().item() for elem in menu_corrected[:-1]]\n",
        "axes[1, 1].bar(range(len(beta_values)), beta_values, alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_title('Î² Parameters (Raw Values)')\n",
        "axes[1, 1].set_xlabel('Menu Element')\n",
        "axes[1, 1].set_ylabel('Î² Raw Value')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ä¿®æ­£ç‰ˆçµæžœ:\")\n",
        "print(f\"  æœ€çµ‚åŽç›Š: {revenues_corrected[-1]:.6f}\")\n",
        "print(f\"  æœ€çµ‚IRåˆ¶ç´„æº€è¶³çŽ‡: {ir_rates[-1]:.3f}\")\n",
        "print(f\"  ä¾¡æ ¼ç¯„å›²: {min(prices_corrected):.3f} - {max(prices_corrected):.3f}\")\n",
        "print(f\"  å¹³å‡ä¾¡æ ¼: {np.mean(prices_corrected):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tUL4fV9ZO2x",
        "outputId": "4e8124cb-c766-4df2-9da2-3fb11bdecf86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ“‹ MENU VISUALIZATION (showing first 8 items)\n",
            "============================================================\n",
            "\n",
            "ðŸ½ï¸  Menu Item 1: Price = 0.1604\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_1, Item_3, Item_4, Item_6, Item_7, Item_8, Item_9]\n",
            "      5. [Item_0, Item_2, Item_3, Item_5, Item_9]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 2: Price = 0.1456\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_6, Item_8]\n",
            "      5. [Item_0, Item_2, Item_6, Item_7, Item_8]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 3: Price = 0.2305\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_2, Item_3, Item_4, Item_8]\n",
            "      5. [Empty bundle]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 4: Price = 0.1946\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_0, Item_2, Item_3, Item_4, Item_6, Item_9]\n",
            "      5. [Item_0, Item_3, Item_4, Item_9]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 5: Price = 0.1126\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_3, Item_4, Item_6, Item_9]\n",
            "      5. [Item_3, Item_4, Item_5, Item_9]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 6: Price = 0.0778\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_0, Item_2, Item_3, Item_5, Item_8]\n",
            "      5. [Item_0, Item_1, Item_2, Item_5, Item_6]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 7: Price = 0.0596\n",
            "   ðŸ“¦ Generated bundles (7 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_0, Item_1, Item_3, Item_6, Item_7]\n",
            "      5. [Item_4, Item_5, Item_8]\n",
            "      ... and 2 more bundles\n",
            "\n",
            "ðŸ½ï¸  Menu Item 8: Price = 0.1150\n",
            "   ðŸ“¦ Generated bundles (8 unique):\n",
            "      1. [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "      2. [Item_0]\n",
            "      3. [Item_1]\n",
            "      4. [Item_0, Item_3, Item_4, Item_5]\n",
            "      5. [Item_0, Item_1, Item_2, Item_4, Item_6, Item_7, Item_8, Item_9]\n",
            "      ... and 3 more bundles\n",
            "\n",
            "... and 121 more menu items\n",
            "============================================================\n",
            "\n",
            "\\nðŸ“Š æ€§èƒ½è©•ä¾¡:\n",
            "æœŸå¾…åŽå…¥: 0.1481\n",
            "ãƒãƒ¼ãƒ‰å‰²å½“åŽå…¥: 0.0841\n",
            "å¹³å‡åŠ¹ç”¨: 0.5977\n",
            "IRåˆ¶ç´„æº€è¶³çŽ‡: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Detailed menu analysis\n",
        "from bundleflow.models.menu import visualize_menu\n",
        "\n",
        "# Menu visualization\n",
        "t_grid = torch.linspace(0.0, 1.0, steps=stage2_config['ode_steps'], device=device)\n",
        "visualize_menu(flow, menu, t_grid, max_items=8, device=device)\n",
        "\n",
        "# ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®æ€§èƒ½è©•ä¾¡\n",
        "mechanism = Mechanism(flow, menu)\n",
        "test_valuations = valuations[:50]  # ãƒ†ã‚¹ãƒˆç”¨ã«50å€‹ä½¿ç”¨\n",
        "\n",
        "# æœŸå¾…åŽå…¥ã®è¨ˆç®—\n",
        "expected_revenue = mechanism.expected_revenue(test_valuations)\n",
        "print(f\"\\\\n æ€§èƒ½è©•ä¾¡:\")\n",
        "print(f\"Expected Revenue: {expected_revenue.detach().item():.4f}\")\n",
        "\n",
        "# ãƒãƒ¼ãƒ‰å‰²å½“ã§ã®çµæžœ\n",
        "result = mechanism.argmax_menu(test_valuations)\n",
        "print(f\"Revenue: {result['revenue'].detach().item():.4f}\")\n",
        "print(f\"Average Utility: {result['welfare'].detach().item():.4f}\")\n",
        "print(f\"the percentage of satisfication of IR constraints: {result['ir_satisfied'].detach().item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b9c072",
        "outputId": "43be0fba-1bfb-4074-b6f3-5c1065ed7cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n============================================================\n",
            "ðŸ“‹ MENU DETAILS\n",
            "============================================================\n",
            "\\nðŸ½ï¸  Menu Item 1:\n",
            "  Price = 9.1055\n",
            "  Beta (Base Utility) = 9.1055\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9996, 0.0000, 0.0000, 0.0003]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_1, Item_3, Item_4, Item_6, Item_7, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 2:\n",
            "  Price = 9.0449\n",
            "  Beta (Base Utility) = 9.0449\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9999, 0.0000, 0.0000, 0.0000]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_3, Item_5, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 3:\n",
            "  Price = 9.3431\n",
            "  Beta (Base Utility) = 9.3431\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9988, 0.0001, 0.0001, 0.0010]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_4, Item_5, Item_7, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 4:\n",
            "  Price = 8.6947\n",
            "  Beta (Base Utility) = 8.6947\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9203, 0.0083, 0.0051, 0.0663]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_4, Item_5, Item_6, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 5:\n",
            "  Price = 9.0884\n",
            "  Beta (Base Utility) = 9.0884\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9997, 0.0000, 0.0000, 0.0003]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_8]\n",
            "\\nðŸ½ï¸  Menu Item 6:\n",
            "  Price = 9.1175\n",
            "  Beta (Base Utility) = 9.1175\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9990, 0.0002, 0.0002, 0.0006]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_4, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 7:\n",
            "  Price = 9.0528\n",
            "  Beta (Base Utility) = 9.0528\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9999, 0.0000, 0.0000, 0.0001]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_1, Item_2, Item_3, Item_6, Item_8]\n",
            "\\nðŸ½ï¸  Menu Item 8:\n",
            "  Price = 9.0723\n",
            "  Beta (Base Utility) = 9.0723\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9966, 0.0009, 0.0005, 0.0020]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_3, Item_4, Item_6, Item_7]\n",
            "\\nðŸ½ï¸  Menu Item 9:\n",
            "  Price = 8.9665\n",
            "  Beta (Base Utility) = 8.9665\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9951, 0.0026, 0.0014, 0.0009]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_1, Item_4]\n",
            "\\nðŸ½ï¸  Menu Item 10:\n",
            "  Price = 8.8461\n",
            "  Beta (Base Utility) = 8.8461\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9872, 0.0044, 0.0027, 0.0057]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_1, Item_2, Item_6]\n",
            "\\nðŸ½ï¸  Menu Item 11:\n",
            "  Price = 9.5196\n",
            "  Beta (Base Utility) = 9.5196\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9994, 0.0002, 0.0002, 0.0003]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_4, Item_6, Item_7, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 12:\n",
            "  Price = 9.1255\n",
            "  Beta (Base Utility) = 9.1255\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9996, 0.0001, 0.0001, 0.0001]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_4, Item_6, Item_8]\n",
            "\\nðŸ½ï¸  Menu Item 13:\n",
            "  Price = 9.0880\n",
            "  Beta (Base Utility) = 9.0880\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9973, 0.0007, 0.0004, 0.0017]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_6, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 14:\n",
            "  Price = 9.1102\n",
            "  Beta (Base Utility) = 9.1102\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9997, 0.0000, 0.0000, 0.0002]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_3, Item_4, Item_6, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 15:\n",
            "  Price = 9.6983\n",
            "  Beta (Base Utility) = 9.6983\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9990, 0.0002, 0.0002, 0.0006]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_5, Item_6, Item_8, Item_9]\n",
            "\\nðŸ½ï¸  Menu Item 16:\n",
            "  Price = 8.6926\n",
            "  Beta (Base Utility) = 8.6926\n",
            "  Initial Distribution Weights (D=4):\n",
            "    [0.9648, 0.0084, 0.0052, 0.0216]\n",
            "  ðŸ“¦ Generated bundles from each component:\n",
            "    Component 1: [Item_0, Item_1, Item_2, Item_3, Item_4, Item_5, Item_6, Item_7, Item_8, Item_9]\n",
            "    Component 2: [Item_0]\n",
            "    Component 3: [Item_1]\n",
            "    Component 4: [Item_0, Item_2, Item_3, Item_4, Item_7]\n",
            "\\nðŸ½ï¸  Null Item:\n",
            "  Beta (Base Utility) = 0.0000\n",
            "  Initial Distribution Weight (D=1):\n",
            "    [1.0000]\n",
            "  ðŸ“¦ Generated bundle: [Empty bundle]\n",
            "\\n============================================================\n"
          ]
        }
      ],
      "source": [
        "# Display details of each menu element\n",
        "print(\"\\\\n============================================================\")\n",
        "print(\"ðŸ“‹ MENU DETAILS\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "t_grid = torch.linspace(0.0, 1.0, steps=gpu_config['ode_steps'], device=device)\n",
        "\n",
        "# nullè¦ç´ ã‚’é™¤ã„ãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼è¦ç´ ã‚’ãƒ«ãƒ¼ãƒ—\n",
        "for i, elem in enumerate(menu_gpu[:-1]):\n",
        "    print(f\"\\\\nðŸ½ï¸  Menu Item {i + 1}:\")\n",
        "    print(f\"  Price = {elem.price().detach().item():.4f}\")\n",
        "    print(f\"  Beta (Base Utility) = {elem.beta.detach().item():.4f}\")\n",
        "    print(f\"  Initial Distribution Weights (D={gpu_config['D']}):\")\n",
        "    # é‡ã¿ã‚’å°æ•°ç‚¹ä»¥ä¸‹4æ¡ã¾ã§è¡¨ç¤º\n",
        "    weights_str = ', '.join([f\"{w:.4f}\" for w in elem.weights.detach().cpu().numpy()])\n",
        "    print(f\"    [{weights_str}]\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # å„æ··åˆæˆåˆ†ã‹ã‚‰æŸã‚’ç”Ÿæˆ\n",
        "        print(\"  ðŸ“¦ Generated bundles from each component:\")\n",
        "        for d in range(gpu_config['D']):\n",
        "            # å„æˆåˆ†ã®Î¼ã‚’å–å¾—ã—ã€unsqueeze(0)ã§ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ \n",
        "            mu_d = elem.mus[d].unsqueeze(0)\n",
        "            x_T_d = flow.flow_forward(mu_d, t_grid)\n",
        "            bundle_d = flow.round_to_bundle(x_T_d)\n",
        "\n",
        "            # æŸã‚’ã‚¢ã‚¤ãƒ†ãƒ åä»˜ãã§è¡¨ç¤º\n",
        "            bundle_items = [f\"Item_{j}\" for j, val in enumerate(bundle_d[0]) if val == 1]\n",
        "            if not bundle_items:\n",
        "                bundle_str = \"[Empty bundle]\"\n",
        "            else:\n",
        "                bundle_str = \"[\" + \", \".join(bundle_items) + \"]\"\n",
        "            print(f\"    Component {d+1}: {bundle_str}\")\n",
        "\n",
        "# nullè¦ç´ ã®è©³ç´°\n",
        "print(\"\\\\nðŸ½ï¸  Null Item:\")\n",
        "print(f\"  Beta (Base Utility) = {menu_gpu[-1].beta.detach().item():.4f}\")\n",
        "print(f\"  Initial Distribution Weight (D=1):\")\n",
        "print(f\"    [{menu_gpu[-1].weights.detach().item():.4f}]\")\n",
        "with torch.no_grad():\n",
        "    null_mu = menu_gpu[-1].mus\n",
        "    null_x_T = flow.flow_forward(null_mu, t_grid)\n",
        "    null_bundle = flow.round_to_bundle(null_x_T)\n",
        "    null_items = [f\"Item_{j}\" for j, val in enumerate(null_bundle[0]) if val == 1]\n",
        "    if not null_items:\n",
        "        null_str = \"[Empty bundle]\"\n",
        "    else:\n",
        "        null_str = \"[\" + \", \".join(null_items) + \"]\"\n",
        "print(f\"  Generated bundle: {null_str}\")\n",
        "\n",
        "print(\"\\\\n============================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a630438",
        "outputId": "c472a51c-cbae-4196-d6ad-0f0bff89a4fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Trained flow model saved to flow_model.pth\n",
            "âœ… Optimized menu saved to optimized_menu.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define file paths\n",
        "flow_model_path = 'flow_model.pth'\n",
        "optimized_menu_path = 'optimized_menu.pth'\n",
        "\n",
        "# Save the trained flow model state dictionary\n",
        "try:\n",
        "    torch.save(flow.state_dict(), flow_model_path)\n",
        "    print(f\"âœ… Trained flow model saved to {flow_model_path}\")\n",
        "except NameError:\n",
        "    print(\"âŒ Error: 'flow' model not found. Please ensure Stage1 training was completed.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error saving flow model: {e}\")\n",
        "\n",
        "\n",
        "# Save the optimized menu\n",
        "try:\n",
        "    torch.save(menu_gpu, optimized_menu_path)\n",
        "    print(f\"âœ… Optimized menu saved to {optimized_menu_path}\")\n",
        "except NameError:\n",
        "    print(\"âŒ Error: 'menu_gpu' not found. Please ensure Stage2 training was completed.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error saving optimized menu: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836902eb"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the saved flow model state dictionary and the optimized menu from files and verify by printing details of the loaded menu.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "a7046bc3",
        "outputId": "892f3108-3628-4afa-ae05-57536aed0b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Flow model state dictionary loaded from flow_model.pth\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL bundleflow.models.menu.MenuElement was not an allowed global by default. Please use `torch.serialization.add_safe_globals([bundleflow.models.menu.MenuElement])` or the `torch.serialization.safe_globals([bundleflow.models.menu.MenuElement])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3299276576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the saved optimized menu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloaded_menu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_menu_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Optimized menu loaded from {optimized_menu_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                         )\n\u001b[1;32m   1528\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 return _load(\n\u001b[1;32m   1531\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL bundleflow.models.menu.MenuElement was not an allowed global by default. Please use `torch.serialization.add_safe_globals([bundleflow.models.menu.MenuElement])` or the `torch.serialization.safe_globals([bundleflow.models.menu.MenuElement])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "# Load the saved flow model state dictionary\n",
        "loaded_flow_state_dict = torch.load(flow_model_path)\n",
        "print(f\"âœ… Flow model state dictionary loaded from {flow_model_path}\")\n",
        "\n",
        "# Load the saved optimized menu\n",
        "loaded_menu = torch.load(optimized_menu_path)\n",
        "print(f\"âœ… Optimized menu loaded from {optimized_menu_path}\")\n",
        "\n",
        "# Create a new BundleFlow model instance and load the state dictionary\n",
        "# Assuming stage1_config is available to get the number of items 'm'\n",
        "try:\n",
        "    loaded_flow = BundleFlow(m=stage1_config['m']).to(device)\n",
        "    loaded_flow.load_state_dict(loaded_flow_state_dict)\n",
        "    print(\"âœ… Flow model loaded successfully into a new instance\")\n",
        "except NameError:\n",
        "    print(\"âŒ Error: 'stage1_config' not found. Cannot initialize new flow model.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading flow model state dictionary: {e}\")\n",
        "\n",
        "\n",
        "# Verify the loaded menu by printing details of the first and last elements\n",
        "try:\n",
        "    if loaded_menu:\n",
        "        # First menu item (assuming not the null element)\n",
        "        first_item = loaded_menu[0]\n",
        "        print(f\"\\nLoaded Menu - First Item Price: {first_item.price().detach().item():.4f}\")\n",
        "\n",
        "        # Last menu item (assuming it's the null element)\n",
        "        last_item = loaded_menu[-1]\n",
        "        # Check if it's the null element by checking if it has a beta property\n",
        "        if hasattr(last_item, 'beta'):\n",
        "             print(f\"Loaded Menu - Last (Null) Item Beta: {last_item.beta.detach().item():.4f}\")\n",
        "        else:\n",
        "             print(f\"Loaded Menu - Last Item Price: {last_item.price().detach().item():.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Loaded menu is empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error verifying loaded menu: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1e9b08"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to load the menu failed because `torch.load` defaults to `weights_only=True` in recent versions of PyTorch, and the saved object (`MenuElement` instances) is not just weights. To load the custom class instances, I need to explicitly set `weights_only=False`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2rxFntfuxhG",
        "outputId": "79417437-62e6-481b-d3d1-55007b16a375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Flow model state dictionary loaded from flow_model.pth\n",
            "âœ… Optimized menu loaded from optimized_menu.pth with weights_only=False\n",
            "âœ… Flow model loaded successfully into a new instance\n",
            "\n",
            "Loaded Menu - First Item Price: 9.1055\n",
            "Loaded Menu - Last (Null) Item Beta: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define file paths (assuming they are already defined in a previous cell)\n",
        "# flow_model_path = 'flow_model.pth'\n",
        "# optimized_menu_path = 'optimized_menu.pth'\n",
        "\n",
        "# Load the saved flow model state dictionary (this part was successful)\n",
        "loaded_flow_state_dict = torch.load(flow_model_path)\n",
        "print(f\"âœ… Flow model state dictionary loaded from {flow_model_path}\")\n",
        "\n",
        "# Load the saved optimized menu with weights_only=False to allow loading custom classes\n",
        "try:\n",
        "    loaded_menu = torch.load(optimized_menu_path, weights_only=False)\n",
        "    print(f\"âœ… Optimized menu loaded from {optimized_menu_path} with weights_only=False\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading optimized menu with weights_only=False: {e}\")\n",
        "\n",
        "\n",
        "# Create a new BundleFlow model instance and load the state dictionary\n",
        "# Assuming stage1_config is available to get the number of items 'm'\n",
        "try:\n",
        "    # Check if 'stage1_config' is defined\n",
        "    if 'stage1_config' not in globals():\n",
        "        print(\"âŒ Error: 'stage1_config' not found. Cannot initialize new flow model.\")\n",
        "        loaded_flow = None # Set to None to avoid errors later\n",
        "    else:\n",
        "        loaded_flow = BundleFlow(m=stage1_config['m']).to(device)\n",
        "        loaded_flow.load_state_dict(loaded_flow_state_dict)\n",
        "        print(\"âœ… Flow model loaded successfully into a new instance\")\n",
        "except NameError:\n",
        "     # This catch is redundant if the check above is done, but kept for robustness\n",
        "    print(\"âŒ Error: 'stage1_config' not found during BundleFlow initialization.\")\n",
        "    loaded_flow = None\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading flow model state dictionary: {e}\")\n",
        "\n",
        "\n",
        "# Verify the loaded menu by printing details of the first and last elements\n",
        "try:\n",
        "    if loaded_menu:\n",
        "        # Ensure loaded_menu is a list and not empty\n",
        "        if isinstance(loaded_menu, list) and len(loaded_menu) > 0:\n",
        "            # First menu item (assuming not the null element)\n",
        "            first_item = loaded_menu[0]\n",
        "            # Check if the first item is a MenuElement and has a price method\n",
        "            if isinstance(first_item, MenuElement) and hasattr(first_item, 'price'):\n",
        "                 print(f\"\\nLoaded Menu - First Item Price: {first_item.price().detach().item():.4f}\")\n",
        "            else:\n",
        "                 print(f\"\\nLoaded Menu - First item is not a recognized MenuElement.\")\n",
        "\n",
        "\n",
        "            # Last menu item (assuming it's the null element)\n",
        "            last_item = loaded_menu[-1]\n",
        "            # Check if the last item is a MenuElement and has a beta property (characteristic of null element)\n",
        "            if isinstance(last_item, MenuElement) and hasattr(last_item, 'beta'):\n",
        "                 print(f\"Loaded Menu - Last (Null) Item Beta: {last_item.beta.detach().item():.4f}\")\n",
        "            elif isinstance(last_item, MenuElement) and hasattr(last_item, 'price'): # Fallback if null element also has price\n",
        "                 print(f\"Loaded Menu - Last Item Price: {last_item.price().detach().item():.4f}\")\n",
        "            else:\n",
        "                 print(f\"Loaded Menu - Last item is not a recognized MenuElement.\")\n",
        "\n",
        "        else:\n",
        "             print(\"âŒ Loaded menu is not a valid list or is empty.\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Loaded menu is None.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error verifying loaded menu: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d5bd78a"
      },
      "source": [
        "## Enhanced Performance Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Generate or use more test valuation functions and calculate performance metrics such as expected revenue, hard assignment revenue, average utility, and IR constraint satisfaction rate for the mechanism (`Mechanism`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e6bb740"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate more test valuation functions for enhanced performance evaluation, create a new Mechanism instance with the loaded flow model and menu, and calculate and print the performance metrics (expected revenue, hard assignment revenue, welfare, and IR satisfaction rate).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493d8617",
        "outputId": "8fe52f8f-5107-4d36-ad2d-ae6433f4b6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Generating 400 test XOR valuations...\n",
            "  Generating test valuation 100/400\n",
            "  Generating test valuation 200/400\n",
            "  Generating test valuation 300/400\n",
            "  Generating test valuation 400/400\n",
            "âœ… 400 test valuations generated.\n",
            "\n",
            "âœ… Mechanism instance created with loaded flow and menu.\n",
            "\n",
            "ðŸ“Š Evaluating Mechanism Performance on Test Valuations:\n",
            "Expected Revenue (Soft Assignment): 7.9691\n",
            "Hard Assignment Revenue: 0.0000\n",
            "Average Welfare (Hard Assignment): 0.0000\n",
            "IR Constraint Satisfaction Rate (Hard Assignment): 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Generate more test evaluation functions\n",
        "num_test_valuations = gpu_config['n_val'] * 2  # Twice the number used for training\n",
        "test_valuations = []\n",
        "print(f\"\\nðŸ“Š Generating {num_test_valuations} test XOR valuations...\")\n",
        "for i in range(num_test_valuations):\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"  Generating test valuation {i+1}/{num_test_valuations}\")\n",
        "    # Use a different seed for test data\n",
        "    v = gen_uniform_iid_xor(\n",
        "        m=gpu_config['m'],\n",
        "        a=gpu_config['a'],\n",
        "        low=0.0,\n",
        "        high=1.0,\n",
        "        seed=gpu_config['seed'] + i + 1000, # Use a distinct seed range\n",
        "        atom_size_mode=\"small\"\n",
        "    )\n",
        "    test_valuations.append(v)\n",
        "\n",
        "print(f\"âœ… {len(test_valuations)} test valuations generated.\")\n",
        "\n",
        "# Create a new Mechanism instance using the loaded flow and menu\n",
        "# Ensure loaded_flow and loaded_menu are available from previous steps\n",
        "if 'loaded_flow' not in globals() or loaded_flow is None:\n",
        "    print(\"âŒ Error: loaded_flow model not found. Cannot create Mechanism.\")\n",
        "elif 'loaded_menu' not in globals() or loaded_menu is None:\n",
        "     print(\"âŒ Error: loaded_menu not found. Cannot create Mechanism.\")\n",
        "else:\n",
        "    mechanism = Mechanism(loaded_flow, loaded_menu)\n",
        "    print(\"\\nâœ… Mechanism instance created with loaded flow and menu.\")\n",
        "\n",
        "    # Calculate and print performance metrics\n",
        "    print(\"\\nðŸ“Š Evaluating Mechanism Performance on Test Valuations:\")\n",
        "\n",
        "    # Expected Revenue (using soft assignment)\n",
        "    try:\n",
        "        expected_revenue = mechanism.expected_revenue(test_valuations)\n",
        "        print(f\"Expected Revenue (Soft Assignment): {expected_revenue.detach().item():.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error calculating expected revenue: {e}\")\n",
        "\n",
        "    # Performance metrics with Hard Assignment (argmax)\n",
        "    try:\n",
        "        result_hard_assignment = mechanism.argmax_menu(test_valuations)\n",
        "        print(f\"Hard Assignment Revenue: {result_hard_assignment['revenue'].detach().item():.4f}\")\n",
        "        print(f\"Average Welfare (Hard Assignment): {result_hard_assignment['welfare'].detach().item():.4f}\")\n",
        "        print(f\"IR Constraint Satisfaction Rate (Hard Assignment): {result_hard_assignment['ir_satisfied'].detach().item():.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error calculating hard assignment metrics: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3126a44"
      },
      "source": [
        "**Reasoning**:\n",
        "The performance metrics calculated using the hard assignment (argmax) show zero revenue and welfare, which is unexpected. This suggests an issue with how the hard assignment is being calculated or interpreted, or potentially an issue with the generated bundles not aligning well with the valuations in a hard assignment setting. I need to investigate the hard assignment results more closely to understand why the revenue and welfare are zero, while the IR constraint is satisfied. I will print more details about the hard assignment results, specifically looking at the assigned bundles and utilities for a few example test valuations, to see if the argmax selection is consistently picking the null bundle (which has zero price and value).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3538154",
        "outputId": "de7c4f9a-dc7f-454a-d2c5-8aa2a0e08d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Analyzing Hard Assignment Results for a few test valuations:\n",
            "\n",
            "--- Test Valuation 1 ---\n",
            "  Assigned Menu Item Index: 16\n",
            "  Assigned Utility: 0.0000\n",
            "  Assigned Price: 0.0000\n",
            "  Assigned Element Beta: 0.0000\n",
            "  Assigned Bundle: [Empty bundle] (Null Element)\n",
            "  Actual Value for Empty Bundle: 0.0000\n",
            "\n",
            "--- Test Valuation 2 ---\n",
            "  Assigned Menu Item Index: 16\n",
            "  Assigned Utility: 0.0000\n",
            "  Assigned Price: 0.0000\n",
            "  Assigned Element Beta: 0.0000\n",
            "  Assigned Bundle: [Empty bundle] (Null Element)\n",
            "  Actual Value for Empty Bundle: 0.0000\n",
            "\n",
            "--- Test Valuation 3 ---\n",
            "  Assigned Menu Item Index: 16\n",
            "  Assigned Utility: 0.0000\n",
            "  Assigned Price: 0.0000\n",
            "  Assigned Element Beta: 0.0000\n",
            "  Assigned Bundle: [Empty bundle] (Null Element)\n",
            "  Actual Value for Empty Bundle: 0.0000\n",
            "\n",
            "--- Test Valuation 4 ---\n",
            "  Assigned Menu Item Index: 16\n",
            "  Assigned Utility: 0.0000\n",
            "  Assigned Price: 0.0000\n",
            "  Assigned Element Beta: 0.0000\n",
            "  Assigned Bundle: [Empty bundle] (Null Element)\n",
            "  Actual Value for Empty Bundle: 0.0000\n",
            "\n",
            "--- Test Valuation 5 ---\n",
            "  Assigned Menu Item Index: 16\n",
            "  Assigned Utility: 0.0000\n",
            "  Assigned Price: 0.0000\n",
            "  Assigned Element Beta: 0.0000\n",
            "  Assigned Bundle: [Empty bundle] (Null Element)\n",
            "  Actual Value for Empty Bundle: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Analyze hard assignment results more closely\n",
        "print(\"\\n Analyzing Hard Assignment Results for a few test valuations:\")\n",
        "\n",
        "# Select a few test valuations to inspect\n",
        "num_examples = 5\n",
        "example_valuations = test_valuations[:num_examples]\n",
        "\n",
        "# Get the hard assignment results for these examples\n",
        "example_result = mechanism.argmax_menu(example_valuations)\n",
        "\n",
        "# Print details for each example valuation\n",
        "for i in range(num_examples):\n",
        "    valuation = example_valuations[i]\n",
        "    assigned_index = example_result['assignments'][i].item()\n",
        "    assigned_utility = example_result['utilities'][i].item()\n",
        "    assigned_price = example_result['prices'][i].item()\n",
        "\n",
        "    print(f\"\\n--- Test Valuation {i+1} ---\")\n",
        "    print(f\"  Assigned Menu Item Index: {assigned_index}\")\n",
        "    print(f\"  Assigned Utility: {assigned_utility:.4f}\")\n",
        "    print(f\"  Assigned Price: {assigned_price:.4f}\")\n",
        "\n",
        "    # Retrieve the assigned menu element\n",
        "    assigned_element = loaded_menu[assigned_index]\n",
        "    print(f\"  Assigned Element Beta: {assigned_element.beta.detach().item():.4f}\")\n",
        "\n",
        "    # If it's the null element, the bundle is empty\n",
        "    if assigned_element == loaded_menu[-1]:\n",
        "        print(\"  Assigned Bundle: [Empty bundle] (Null Element)\")\n",
        "        actual_value = valuation.value(torch.zeros(gpu_config['m']))\n",
        "        print(f\"  Actual Value for Empty Bundle: {actual_value:.4f}\")\n",
        "    else:\n",
        "        # Generate the bundle from the assigned element's initial distribution\n",
        "        # Note: In the argmax_menu, the bundle is determined by the component\n",
        "        # that yields the maximum utility *after* flow and rounding.\n",
        "        # We can't easily reproduce the exact bundle here without re-running\n",
        "        # the flow for all components and finding the argmax component.\n",
        "        # Instead, let's just indicate it's a non-null bundle.\n",
        "        print(f\"  Assigned Bundle: Generated from Menu Item {assigned_index + 1}\")\n",
        "\n",
        "        # Calculate the value of the generated bundle from each component\n",
        "        # for this specific valuation to understand the utility calculation\n",
        "        print(f\"  Utility breakdown per component for assigned item {assigned_index + 1}:\")\n",
        "        with torch.no_grad():\n",
        "            t_grid = torch.linspace(0.0, 1.0, steps=gpu_config['ode_steps'], device=device)\n",
        "            mus_item = assigned_element.mus.unsqueeze(0) # Add batch dimension\n",
        "            sT_item = flow.flow_forward(mus_item.view(-1, gpu_config['m']), t_grid)\n",
        "            s_item = flow.round_to_bundle(sT_item) # (D, m)\n",
        "\n",
        "            # Calculate value for each bundle\n",
        "            if hasattr(valuation, 'batch_value'):\n",
        "                 vals_item = valuation.batch_value(s_item.cpu()).to(device) # (D,)\n",
        "            else:\n",
        "                 vals_item = torch.tensor([valuation.value(s.cpu()) for s in s_item], device=device, dtype=torch.float32)\n",
        "\n",
        "            # Calculate log density weight for each bundle\n",
        "            log_density_item = flow.log_density_weight(mus_item.view(-1, gpu_config['m']), t_grid)\n",
        "            log_density_item = torch.clamp(log_density_item, -10.0, 0.0) # (D,)\n",
        "\n",
        "            # Calculate utilities for each component\n",
        "            log_w_item = torch.log(assigned_element.weights + 1e-10) # (D,)\n",
        "            log_weights_item = log_w_item + log_density_item # (D,)\n",
        "            log_weights_item = torch.clamp(log_weights_item, -50.0, 50.0) # (D,)\n",
        "\n",
        "            utilities_per_component = torch.exp(log_weights_item) * vals_item - assigned_element.beta # (D,)\n",
        "\n",
        "            for d in range(gpu_config['D']):\n",
        "                 print(f\"    Component {d+1}: Bundle Value={vals_item[d].item():.4f}, Log Weight={log_weights_item[d].item():.4f}, Utility={utilities_per_component[d].item():.4f}\")\n",
        "\n",
        "            # Check the max utility across components\n",
        "            max_utility_component, max_comp_index = torch.max(utilities_per_component, dim=0)\n",
        "            print(f\"    Max Utility Component: {max_comp_index.item() + 1} (Utility: {max_utility_component.item():.4f})\")\n",
        "            print(f\"    argmax_menu assigned utility: {assigned_utility:.4f}\") # Should match max_utility_component if this item was chosen\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
